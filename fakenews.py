# -*- coding: utf-8 -*-
"""FakeNews.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15gXd7VKR2goo0UrnKO3obX6GnL8_cImo
"""

from google.colab import files
files.upload()

from pyngrok import ngrok

# Disconnect all active tunnels
for tunnel in ngrok.get_tunnels():
    ngrok.disconnect(tunnel.public_url)

# Install dependencies
!pip install -q streamlit transformers scikit-learn pyngrok kaggle torch seaborn matplotlib

import os
os.makedirs('/root/.kaggle', exist_ok=True)
!cp kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

# Download Kaggle dataset
!kaggle datasets download -d clmentbisaillon/fake-and-real-news-dataset --unzip

import pandas as pd
import subprocess
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

# Load
df_fake = pd.read_csv('Fake.csv')
df_real = pd.read_csv('True.csv')

# Use only 'title' column
df_fake['label'] = 'FAKE'
df_real['label'] = 'REAL'

df = pd.concat([df_fake, df_real], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)
df = df[['title', 'label']].dropna()

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    df['title'], df['label'], test_size=0.3, random_state=42, stratify=df['label'])

# Vectorize titles
vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Train Logistic Regression baseline
model = LogisticRegression(max_iter=500)
model.fit(X_train_tfidf, y_train)

# Evaluate baseline
y_pred = model.predict(X_test_tfidf)
acc = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred, output_dict=True)
cm = confusion_matrix(y_test, y_pred)

print(f"Baseline Logistic Regression on Title only - Accuracy: {acc:.2%}")

# Write Streamlit app
app_code = f"""
import streamlit as st
from transformers import pipeline, set_seed
import torch
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

st.set_page_config(page_title="Fake News Detector (Title)", layout="wide")
st.title("Fake News Detector and Generator")

@st.cache_data
def load_data():
    df_fake = pd.read_csv('Fake.csv')
    df_real = pd.read_csv('True.csv')
    df_fake['label'] = 'FAKE'
    df_real['label'] = 'REAL'
    df = pd.concat([df_fake, df_real], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)
    return df[['title', 'label']].dropna()

DATA = load_data()

# Load baseline TF-IDF model and vectorizer from serialized state (simulate here by retraining)
@st.cache_resource
def train_baseline():
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split

    X = DATA['title']
    y = DATA['label']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
    vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)
    X_train_tfidf = vectorizer.fit_transform(X_train)
    model = LogisticRegression(max_iter=500)
    model.fit(X_train_tfidf, y_train)
    X_test_tfidf = vectorizer.transform(X_test)
    y_pred = model.predict(X_test_tfidf)
    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
    acc = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, output_dict=True)
    cm = confusion_matrix(y_test, y_pred)
    return model, vectorizer, acc, report, cm

model, vectorizer, acc, report, cm = train_baseline()

# Initialize transformers pipeline for detection
@st.cache_resource
def get_transformer_pipeline():
    model_name = 'distilbert-base-uncased-finetuned-sst-2-english'
    device = 0 if torch.cuda.is_available() else -1
    return pipeline('text-classification', model=model_name, tokenizer=model_name, device=device)
detector = get_transformer_pipeline()

@st.cache_resource
def get_generator():
    gen = pipeline("text-generation", model="gpt2", device=0 if torch.cuda.is_available() else -1)
    set_seed(42)
    return gen
generator = get_generator()

page = st.sidebar.radio("Navigation", ["Detect Fake News", "Generate Fake News", "Metrics", "Sample Titles"])

if page == "Detect Fake News":
    st.header("Fake News Detection (Title Only)")
    user_title = st.text_input("Enter the article title here:")
    method = st.selectbox("Choose detection method:", ["Transformer Pipeline (DistilBERT)", "TF-IDF + Logistic Regression Baseline"])
    if st.button("Detect"):
        if user_title.strip() == "":
            st.warning("Please enter a title for detection.")
        else:
            if method == "Transformer Pipeline (DistilBERT)":
                label_map = {{"NEGATIVE":"FAKE", "POSITIVE":"REAL"}}
                preds = detector(user_title, truncation=True)
                pred_label = label_map.get(preds[0]['label'], preds[0]['label'])
                confidence = preds[0]['score']
                st.success(f"Prediction (Transformer): **{{pred_label}}** (Confidence: {{confidence:.2%}})")
                st.json(preds[0])
            else:
                X_vec = vectorizer.transform([user_title])
                pred = model.predict(X_vec)[0]
                proba = max(model.predict_proba(X_vec)[0])
                st.success(f"Prediction (Baseline): **{{pred}}** (Confidence: {{proba:.2%}})")

elif page == "Generate Fake News":
    st.header("Fake News Text Generation (Title Only Prompt)")
    st.warning("Use generated text responsibly for research only.")
    prompt = st.text_input("Enter a seed title for generation:", "Scientists discover breakthrough in renewable energy")
    max_len = st.slider("Max generation length", 50, 200, 100, step=10)
    temperature = st.slider("Sampling temperature", 0.5, 1.5, 1.0, step=0.1)
    n_samples = st.slider("Number of samples", 1, 3, 1)
    if st.button("Generate"):
        st.info("Generating fake news text...")
        results = generator(prompt, max_length=max_len, num_return_sequences=n_samples, temperature=temperature)
        for i, r in enumerate(results):
            st.markdown(f"### Sample {{i+1}}")
            st.write(r['generated_text'])
            st.write("---")

elif page == "Metrics":
    st.header("Baseline Model Performance (TF-IDF + Logistic Regression)")
    st.write(f"Accuracy on test set: {{acc:.2%}}")
    st.subheader("Classification Report")
    st.dataframe(pd.DataFrame(report).transpose())
    st.subheader("Confusion Matrix")
    fig, ax = plt.subplots()
    sns.heatmap(cm, annot=True, fmt="d", xticklabels=["FAKE", "REAL"], yticklabels=["FAKE", "REAL"], cmap="Blues", ax=ax)
    ax.set_xlabel("Predicted")
    ax.set_ylabel("Actual")
    st.pyplot(fig)

elif page == "Sample Titles":
    st.header("Sample Titles from Dataset")
    st.dataframe(DATA[['title', 'label']].sample(100))
"""

# Save app
with open('app.py', 'w', encoding='utf-8') as f:
    f.write(app_code)

# Setup ngrok and run Streamlit
from pyngrok import ngrok

NGROK_AUTH_TOKEN = "30gZj4Gu5dsIaL8Ugju0REDhbT9_25dgFRQWDDhEisKGqWVyY"  # <-- CHANGE THIS TO YOUR TOKEN
ngrok.set_auth_token(NGROK_AUTH_TOKEN)

public_url = ngrok.connect(8501, "http")
print(f"Streamlit app is live at: {public_url}")

# Run Streamlit app in background
proc = subprocess.Popen(['streamlit', 'run', 'app.py', '--server.port=8501'])